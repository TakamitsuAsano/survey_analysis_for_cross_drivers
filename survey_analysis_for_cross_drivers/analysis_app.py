import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.tree import DecisionTreeClassifier, export_text, export_graphviz
from sklearn.linear_model import LogisticRegression
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder, StandardScaler
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os
import io
import graphviz
import json
import re
from streamlit_gsheets import GSheetsConnection
from st_copy_to_clipboard import st_copy_to_clipboard

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ---
def setup_japanese_font():
    font_path = "/usr/share/fonts/opentype/ipaexfont-gothic/ipaexg.ttf"
    if os.path.exists(font_path):
        try:
            fm.fontManager.addfont(font_path)
            plt.rcParams['font.family'] = 'IPAexGothic'
        except Exception as e:
            st.error(f"ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    else:
        try:
            plt.rcParams['font.family'] = 'Hiragino Sans'
        except:
            pass

setup_japanese_font()

# --- æ±ºå®šæœ¨ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›ã™ã‚‹é–¢æ•° ---
def get_decision_tree_data(clf, feature_names, class_names):
    n_nodes = clf.tree_.node_count
    feature = clf.tree_.feature
    threshold = clf.tree_.threshold
    impurity = clf.tree_.impurity
    n_node_samples = clf.tree_.n_node_samples
    value = clf.tree_.value
    children_left = clf.tree_.children_left
    children_right = clf.tree_.children_right

    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)
    is_leaves = np.zeros(shape=n_nodes, dtype=bool)
    stack = [(0, 0)]
    
    while len(stack) > 0:
        node_id, depth = stack.pop()
        node_depth[node_id] = depth
        is_split_node = children_left[node_id] != children_right[node_id]
        if is_split_node:
            stack.append((children_left[node_id], depth + 1))
            stack.append((children_right[node_id], depth + 1))
        else:
            is_leaves[node_id] = True

    data = []
    for i in range(n_nodes):
        node_type = "Leaf" if is_leaves[i] else "Node"
        if i == 0: node_type = "Root"
        
        if feature[i] != -2:
            feat_name = feature_names[feature[i]]
            th = threshold[i]
            condition = f"{feat_name} <= {th:.3f}"
        else:
            feat_name = None
            th = None
            condition = None
        
        val = value[i][0]
        class_idx = np.argmax(val)
        pred_class = class_names[class_idx] if class_names is not None else str(class_idx)
        
        row = {
            "Node_ID": i,
            "Depth": node_depth[i],
            "Type": node_type,
            "Condition": condition,
            "Feature": feat_name,
            "Threshold": th,
            "Gini": f"{impurity[i]:.4f}",
            "Samples": n_node_samples[i],
            "Value": str(list(map(int, val))),
            "Predicted_Class": pred_class
        }
        data.append(row)
    
    return pd.DataFrame(data)

# --- JSONãƒ‘ãƒ¼ã‚¹ç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---
def extract_json_config(text):
    json_match = re.search(r'```json\s*({.*?})\s*```', text, re.DOTALL)
    config_str = None
    if json_match:
        config_str = json_match.group(1)
    else:
        fallback_match = re.search(r'\{.*\}', text, re.DOTALL)
        if fallback_match:
            config_str = fallback_match.group(0)
    if config_str:
        try:
            return json.loads(config_str)
        except json.JSONDecodeError:
            return None
    return None

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ç¾¤ (Tab7ç”¨) ---
def cb_update_cross(idx, col):
    st.session_state["sb_cross_index"] = idx
    st.session_state["sb_cross_col"] = col

def cb_update_reg(tgt, feats):
    st.session_state["sb_reg_target"] = tgt
    st.session_state["sb_reg_feature"] = feats
    st.session_state['ai_msg_reg'] = True

def cb_update_tree(tgt, feats):
    st.session_state["sb_tree_target"] = tgt
    st.session_state["sb_tree_feature"] = feats
    st.session_state['ai_msg_tree'] = True

def cb_update_cluster(feats):
    st.session_state["sb_cluster_features"] = feats
    st.session_state['ai_msg_cluster'] = True

# --- é¸æŠè‚¢ã®ä¸¦ã³é †ã‚’å¼·åˆ¶ã™ã‚‹é–¢æ•° ---
def enforce_likert_order(df, col_name):
    likert_order_master = [
        "éå¸¸ã«ãã†æ€ã†", "å¼·ããã†æ€ã†", "ã¨ã¦ã‚‚ãã†æ€ã†", "ãã†æ€ã†", "ã‹ãªã‚Šãã†æ€ã†",
        "ã‚„ã‚„ãã†æ€ã†", "ã©ã¡ã‚‰ã‹ã¨ã„ãˆã°ãã†æ€ã†", "ã©ã¡ã‚‰ã‹ã¨è¨€ãˆã°ãã†æ€ã†",
        "ã©ã¡ã‚‰ã¨ã‚‚ã„ãˆãªã„", "ã©ã¡ã‚‰ã¨ã‚‚è¨€ãˆãªã„", "æ™®é€š",
        "ã©ã¡ã‚‰ã‹ã¨ã„ãˆã°ãã†æ€ã‚ãªã„", "ã©ã¡ã‚‰ã‹ã¨è¨€ãˆã°ãã†æ€ã‚ãªã„", "ã‚ã¾ã‚Šãã†æ€ã‚ãªã„",
        "ãã†æ€ã‚ãªã„", "å…¨ããã†æ€ã‚ãªã„", "å…¨ãæ€ã‚ãªã„"
    ]
    unique_vals = df[col_name].dropna().unique()
    sorter = [x for x in likert_order_master if x in unique_vals]
    remaining = [x for x in unique_vals if x not in sorter]
    sorted_remaining = sorted(remaining, key=lambda x: str(x))
    final_order = sorter + sorted_remaining
    
    if len(sorter) >= 2:
        return pd.Categorical(df[col_name], categories=final_order, ordered=True)
    else:
        return df[col_name]

# ---------------------------------------

st.set_page_config(page_title="ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æ & ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³", layout="wide")
st.title("ğŸ“Š ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆåˆ†æ & ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
st.sidebar.header("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿")
input_method = st.sidebar.radio("ãƒ‡ãƒ¼ã‚¿ã®ç¨®é¡ã‚’é¸æŠ", ["ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ"])

df = None

if input_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
    uploaded_file = st.sidebar.file_uploader("Excelã¾ãŸã¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['xlsx', 'csv'])
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.csv'):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            st.sidebar.success("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸï¼")
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

elif input_method == "Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ":
    st.sidebar.info("äº‹å‰ã«ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ã€Œå…±æœ‰ã€ã«ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
    sheet_url = st.sidebar.text_input("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®URLã‚’å…¥åŠ›")
    
    if sheet_url:
        try:
            conn = st.connection("gsheets", type=GSheetsConnection)
            df = conn.read(spreadsheet=sheet_url, ttl=0)
            st.sidebar.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶šæˆåŠŸï¼")
        except Exception as e:
            st.sidebar.error(f"æ¥ç¶šã‚¨ãƒ©ãƒ¼: Secretsã®è¨­å®šã¾ãŸã¯URLã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n{e}")

# --- åˆ†æãƒ¡ã‚¤ãƒ³å‡¦ç† ---
if df is not None:
    df = df.dropna(how='all')

    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ç¢ºèª", 
        "ğŸ“ˆ ã‚¯ãƒ­ã‚¹é›†è¨ˆ", 
        "ğŸš€ è¦å› (ãƒ‰ãƒ©ã‚¤ãƒãƒ¼)åˆ†æ", 
        "ğŸŒ³ æ±ºå®šæœ¨åˆ†æ", 
        "ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ",
        "ğŸ“– åˆ†ææ‰‹æ³•ã®è§£èª¬(ç”¨èªé›†)",
        "ğŸ¤– AIåˆ†æã‚¢ã‚·ã‚¹ãƒˆ"
    ])

    # --- ã‚¿ãƒ–1: ãƒ‡ãƒ¼ã‚¿ç¢ºèª ---
    with tab1:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        st.dataframe(df)
        st.info(f"ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {df.shape[0]} è¡Œ, {df.shape[1]} åˆ—")

    # --- ã‚¿ãƒ–2: ã‚¯ãƒ­ã‚¹é›†è¨ˆ ---
    with tab2:
        st.subheader("ã‚¯ãƒ­ã‚¹é›†è¨ˆã¨å¯è¦–åŒ–")
        
        col1, col2 = st.columns(2)
        with col1:
            index_col = st.selectbox("è¡Œï¼ˆIndexï¼‰ã‚’é¸æŠ", df.columns, index=0, key="sb_cross_index")
        with col2:
            columns_col = st.selectbox("åˆ—ï¼ˆColumnï¼‰ã‚’é¸æŠ", df.columns, index=min(1, len(df.columns)-1), key="sb_cross_col")

        if index_col == columns_col:
            st.warning("âš ï¸ è¡Œã¨åˆ—ã«ã¯ç•°ãªã‚‹é …ç›®ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            df_cross = df.copy()
            df_cross[index_col] = enforce_likert_order(df_cross, index_col)
            df_cross[columns_col] = enforce_likert_order(df_cross, columns_col)
            
            calc_type = st.radio("é›†è¨ˆå€¤ã®è¡¨ç¤ºå½¢å¼", ["åº¦æ•°ï¼ˆäººæ•°ï¼‰", "è¡Œãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆï¼ˆæ¨ªè¨ˆ=100%ï¼‰", "åˆ—ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆï¼ˆç¸¦è¨ˆ=100%ï¼‰"], horizontal=True)
            
            if calc_type == "åº¦æ•°ï¼ˆäººæ•°ï¼‰":
                cross_tab = pd.crosstab(df_cross[index_col], df_cross[columns_col])
                fmt = ""
                val_name = "äººæ•°"
            elif calc_type == "è¡Œãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆï¼ˆæ¨ªè¨ˆ=100%ï¼‰":
                cross_tab = pd.crosstab(df_cross[index_col], df_cross[columns_col], normalize='index') * 100
                cross_tab = cross_tab.round(1)
                fmt = ".1f"
                val_name = "å‰²åˆ(%)"
            else:
                cross_tab = pd.crosstab(df_cross[index_col], df_cross[columns_col], normalize='columns') * 100
                cross_tab = cross_tab.round(1)
                fmt = ".1f"
                val_name = "å‰²åˆ(%)"

            st.write("##### é›†è¨ˆè¡¨")
            
            copy_text = cross_tab.to_csv(sep='\t')
            st_copy_to_clipboard(copy_text, "ğŸ“‹ è¡¨ã‚’ã‚³ãƒ”ãƒ¼ (ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜)", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
            
            st.dataframe(cross_tab) 

            graph_type = st.radio("ã‚°ãƒ©ãƒ•ã®ç¨®é¡", ["ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—", "ç©ã¿ä¸Šã’æ£’ã‚°ãƒ©ãƒ•"], horizontal=True)
            if graph_type == "ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—":
                fig = px.imshow(cross_tab, text_auto=fmt if fmt else True, aspect="auto", color_continuous_scale='Blues')
            else:
                cross_tab_reset = cross_tab.reset_index().melt(id_vars=index_col, var_name=columns_col, value_name=val_name)
                fig = px.bar(cross_tab_reset, x=index_col, y=val_name, color=columns_col, title=f"{index_col} Ã— {columns_col}", text_auto=fmt if fmt else True)
            st.plotly_chart(fig, use_container_width=True)

    # --- ã‚¿ãƒ–3: è¦å› (ãƒ‰ãƒ©ã‚¤ãƒãƒ¼)åˆ†æ ---
    with tab3:
        st.subheader("ğŸš€ è¦å› ï¼ˆãƒ‰ãƒ©ã‚¤ãƒãƒ¼ï¼‰åˆ†æï¼šã‚ªãƒƒã‚ºæ¯”")
        
        st.info("""
        **ğŸ’¡ æ•°å€¤ã®è¦‹æ–¹ï¼ˆã‚ªãƒƒã‚ºæ¯”ï¼‰**
        * **1.0 ã‚ˆã‚Šå¤§ãã„**: ãã®è¦å› ãŒçµæœã‚’**ä¿ƒé€²**ã—ã¾ã™ã€‚ï¼ˆä¾‹ï¼š2.0ãªã‚‰ã€ãã®è¦å› ãŒã‚ã‚‹ã¨çµæœãŒ2å€èµ·ã“ã‚Šã‚„ã™ã„ï¼‰
        * **1.0 ã‚ˆã‚Šå°ã•ã„**: ãã®è¦å› ãŒçµæœã‚’**æŠ‘åˆ¶**ã—ã¾ã™ã€‚ï¼ˆä¾‹ï¼š0.5ãªã‚‰ã€ãã®è¦å› ãŒã‚ã‚‹ã¨çµæœãŒåŠåˆ†ã—ã‹èµ·ã“ã‚‰ãªã„ï¼‰
        """)

        col1, col2 = st.columns(2)
        with col1:
            target_col_reg = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆåˆ†æã—ãŸã„çµæœï¼‰", df.columns, index=0, key="sb_reg_target")
        with col2:
            valid_options_reg = [c for c in df.columns if c != target_col_reg]
            
            if "sb_reg_feature" in st.session_state:
                current_selection = st.session_state["sb_reg_feature"]
                safe_selection = [x for x in current_selection if x in valid_options_reg]
                st.session_state["sb_reg_feature"] = safe_selection

            default_feats_reg = [c for c in df.columns if c != df.columns[0]][:5]
            safe_default_reg = [x for x in default_feats_reg if x in valid_options_reg]

            feature_cols_reg = st.multiselect(
                "èª¬æ˜å¤‰æ•°ï¼ˆèƒŒæ™¯ãƒ»è¦å› ã¨æ€ã‚ã‚Œã‚‹é …ç›®ï¼‰", 
                valid_options_reg, 
                default=safe_default_reg, 
                key="sb_reg_feature"
            )

        if 'ai_msg_reg' in st.session_state and st.session_state['ai_msg_reg']:
            st.info("âœ… AIãŒãŠã™ã™ã‚è¨­å®šã‚’åæ˜ ã—ã¾ã—ãŸã€‚ä¸‹ã®ã€Œè¦å› åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            st.session_state['ai_msg_reg'] = False

        if st.button("è¦å› åˆ†æã‚’å®Ÿè¡Œ"):
            if not feature_cols_reg:
                st.warning("èª¬æ˜å¤‰æ•°ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    df_reg = df[[target_col_reg] + feature_cols_reg].dropna()
                    
                    for col in df_reg.columns:
                        if df_reg[col].dtype == 'object':
                            le = LabelEncoder()
                            df_reg[col] = df_reg[col].astype(str)
                            df_reg[col] = le.fit_transform(df_reg[col])

                    X = df_reg[feature_cols_reg]
                    y = df_reg[target_col_reg]
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X)

                    model = LogisticRegression(max_iter=1000)
                    model.fit(X_scaled, y)

                    if model.coef_.shape[0] > 1: coefs = model.coef_[-1]
                    else: coefs = model.coef_[0]
                    
                    odds_ratios = np.exp(coefs)
                    res_df = pd.DataFrame({"è¦å› ": feature_cols_reg, "ã‚ªãƒƒã‚ºæ¯”": odds_ratios}).sort_values(by="ã‚ªãƒƒã‚ºæ¯”", ascending=True)

                    st.write(f"### ã€Œ{target_col_reg}ã€ã¸ã®å½±éŸ¿åº¦ï¼ˆã‚ªãƒƒã‚ºæ¯”ï¼‰")
                    fig = px.bar(res_df, x="ã‚ªãƒƒã‚ºæ¯”", y="è¦å› ", orientation='h', 
                                 title=f"ã€Œ{target_col_reg}ã€ã«å¯¾ã™ã‚‹ã‚ªãƒƒã‚ºæ¯”ï¼ˆ1.0ãŒåŸºæº–ï¼‰",
                                 color="ã‚ªãƒƒã‚ºæ¯”", color_continuous_scale="RdBu_r", color_continuous_midpoint=1.0)
                    fig.add_vline(x=1.0, line_width=2, line_dash="dash", line_color="black")
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.write("##### è©³ç´°ãƒ‡ãƒ¼ã‚¿")
                    st_copy_to_clipboard(res_df.to_csv(sep='\t'), "ğŸ“‹ æ•°å€¤ã‚’ã‚³ãƒ”ãƒ¼", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")
                    st.dataframe(res_df)

                except Exception as e:
                    st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    # --- ã‚¿ãƒ–4: æ±ºå®šæœ¨åˆ†æ ---
    with tab4:
        st.subheader("æ±ºå®šæœ¨åˆ†æ")
        st.caption("ğŸ’¡ å›³ã¯ãƒã‚¦ã‚¹ãƒ›ã‚¤ãƒ¼ãƒ«ã§**æ‹¡å¤§ãƒ»ç¸®å°**ã€ãƒ‰ãƒ©ãƒƒã‚°ã§**ç§»å‹•**ãŒã§ãã¾ã™ã€‚")
        
        col1, col2 = st.columns(2)
        with col1:
            target_col_tree = st.selectbox("ç›®çš„å¤‰æ•°ï¼ˆçµæœï¼‰", df.columns, index=0, key="sb_tree_target")
        with col2:
            valid_options = [c for c in df.columns if c != target_col_tree]
            
            if "sb_tree_feature" in st.session_state:
                current_selection = st.session_state["sb_tree_feature"]
                safe_selection = [x for x in current_selection if x in valid_options]
                st.session_state["sb_tree_feature"] = safe_selection

            default_feats = [c for c in df.columns if c != df.columns[0]][:3]
            safe_default = [x for x in default_feats if x in valid_options]

            feature_cols_tree = st.multiselect(
                "èª¬æ˜å¤‰æ•°ï¼ˆè¦å› ï¼‰", 
                valid_options, 
                default=safe_default, 
                key="sb_tree_feature"
            )

        if 'ai_msg_tree' in st.session_state and st.session_state['ai_msg_tree']:
            st.info("âœ… AIãŒãŠã™ã™ã‚è¨­å®šã‚’åæ˜ ã—ã¾ã—ãŸã€‚ä¸‹ã®ã€Œæ±ºå®šæœ¨åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            st.session_state['ai_msg_tree'] = False

        if st.button("æ±ºå®šæœ¨åˆ†æã‚’å®Ÿè¡Œ"):
            if not feature_cols_tree:
                st.warning("èª¬æ˜å¤‰æ•°ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
            else:
                try:
                    df_ml = df.copy()
                    
                    class_names_list = None
                    if df_ml[target_col_tree].dtype == 'object':
                        le_target = LabelEncoder()
                        df_ml[target_col_tree] = df_ml[target_col_tree].astype(str)
                        df_ml[target_col_tree] = le_target.fit_transform(df_ml[target_col_tree])
                        class_names_list = le_target.classes_.astype(str).tolist()
                    else:
                        class_names_list = sorted(df_ml[target_col_tree].unique().astype(str).tolist())

                    for col in feature_cols_tree:
                        if df_ml[col].dtype == 'object':
                            df_ml[col] = df_ml[col].astype(str)
                            le = LabelEncoder()
                            df_ml[col] = le.fit_transform(df_ml[col])

                    df_ml = df_ml.dropna(subset=[target_col_tree] + feature_cols_tree)
                    X = df_ml[feature_cols_tree]
                    y = df_ml[target_col_tree]

                    clf = DecisionTreeClassifier(max_depth=3, random_state=42)
                    clf.fit(X, y)

                    tree_rules = export_text(clf, feature_names=feature_cols_tree)
                    st.write("##### ğŸ“‹ åˆ†å²æ¡ä»¶ã®ãƒ†ã‚­ã‚¹ãƒˆè©³ç´°")
                    st_copy_to_clipboard(tree_rules, "ğŸ“‹ åˆ†å²ãƒ«ãƒ¼ãƒ«ã‚’ã‚³ãƒ”ãƒ¼", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")
                    st.code(tree_rules)

                    dot_data = export_graphviz(
                        clf, out_file=None, feature_names=feature_cols_tree, class_names=class_names_list,
                        filled=True, rounded=True, special_characters=True, fontname="IPAexGothic"
                    )
                    st.graphviz_chart(dot_data)
                    
                    try:
                        graph = graphviz.Source(dot_data)
                        png_bytes = graph.pipe(format='png')
                        st.download_button("ğŸ“¥ æ±ºå®šæœ¨ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (PNG)", png_bytes, "decision_tree.png", "image/png")
                    except: pass

                    st.divider()
                    st.write("##### ğŸ“Š æ±ºå®šæœ¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                    tree_df = get_decision_tree_data(clf, feature_cols_tree, class_names_list)
                    st.download_button("ğŸ“¥ æ±ºå®šæœ¨ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", tree_df.to_csv(index=False).encode('utf-8_sig'), "decision_tree_data.csv", "text/csv")

                except Exception as e:
                    st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    # --- ã‚¿ãƒ–5: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ ---
    with tab5:
        st.subheader("ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰")
        
        cluster_features = st.multiselect(
            "ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã«ä½¿ã†å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„",
            df.columns,
            default=df.columns[:5].tolist(),
            key="sb_cluster_features"
        )
        
        n_clusters = st.slider("åˆ†é¡ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—æ•°", 2, 10, 4)

        if 'ai_msg_cluster' in st.session_state and st.session_state['ai_msg_cluster']:
            st.info("âœ… AIãŒãŠã™ã™ã‚è¨­å®šã‚’åæ˜ ã—ã¾ã—ãŸã€‚ä¸‹ã®ã€Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
            st.session_state['ai_msg_cluster'] = False

        if st.button("ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã‚’å®Ÿè¡Œ"):
            if not cluster_features:
                st.warning("å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„")
            else:
                try:
                    df_cluster = df[cluster_features].dropna()
                    
                    for col in df_cluster.columns:
                        if df_cluster[col].dtype == 'object':
                            le = LabelEncoder()
                            df_cluster[col] = df_cluster[col].astype(str)
                            df_cluster[col] = le.fit_transform(df_cluster[col])

                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(df_cluster)
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                    clusters = kmeans.fit_predict(X_scaled)
                    
                    df['Cluster'] = clusters
                    df['Cluster_Name'] = df['Cluster'].apply(lambda x: f"ã‚°ãƒ«ãƒ¼ãƒ— {x+1}")
                    st.success(f"{n_clusters}ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ã—ã¾ã—ãŸï¼")

                    cluster_means_numeric = df_cluster.copy()
                    cluster_means_numeric['Cluster_Name'] = df['Cluster_Name']
                    cluster_means_numeric = cluster_means_numeric.groupby('Cluster_Name').mean()

                    st.write("##### ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®å›ç­”å‚¾å‘ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰")
                    fig = px.imshow(cluster_means_numeric, text_auto=".2f", aspect="auto", color_continuous_scale="Viridis", title="ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã”ã¨ã®ç‰¹å¾´æ¯”è¼ƒ")
                    st.plotly_chart(fig, use_container_width=True)

                    st.write("##### åˆ†é¡çµæœä»˜ããƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                    st.download_button("ğŸ“¥ åˆ†é¡çµæœä»˜ãCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df.to_csv(index=False).encode('utf-8_sig'), 'clustered_data.csv', 'text/csv')
                    st.write("##### ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®äººæ•°")
                    st.dataframe(df['Cluster_Name'].value_counts().reset_index().rename(columns={'index':'Group', 'Cluster_Name':'Count'}))

                except Exception as e:
                    st.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    # --- ã‚¿ãƒ–6: è§£èª¬ ---
    with tab6:
        st.header("ğŸ“– çµ±è¨ˆåˆ†ææ‰‹æ³•ã®è§£èª¬ã‚¬ã‚¤ãƒ‰")
        st.markdown("ï¼ˆè©³ç´°ã¯çœç•¥ã—ã¾ã™ã€‚ï¼‰")
        st.info("è©³ã—ã„è§£èª¬ã¯ã€Œåˆ†ææ‰‹æ³•ã®è§£èª¬ã€ã‚¿ãƒ–ã‚’ã”å‚ç…§ãã ã•ã„ã€‚")

    # --- ã‚¿ãƒ–7: AIåˆ†æã‚¢ã‚·ã‚¹ãƒˆ (ç´°åˆ†åŒ–ç‰ˆ) ---
    with tab7:
        st.header("ğŸ¤– AIåˆ†æã‚¢ã‚·ã‚¹ãƒˆ")
        st.markdown("é•·æ–‡ã‚„ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã€åˆ†ææ‰‹æ³•ã”ã¨ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†å‰²ã—ã¦ã„ã¾ã™ã€‚ç›®çš„ã®ã‚¿ãƒ–ã‚’é–‹ã„ã¦ã€AIã«æŒ‡ç¤ºã‚’å‡ºã—ã¦ãã ã•ã„ã€‚")
        
        ai_tab1, ai_tab2, ai_tab3, ai_tab4 = st.tabs([
            "ğŸ“ˆ ã‚¯ãƒ­ã‚¹é›†è¨ˆ", 
            "ğŸš€ ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æ", 
            "ğŸŒ³ æ±ºå®šæœ¨åˆ†æ", 
            "ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ"
        ])

        # ==========================================
        # ã‚¯ãƒ­ã‚¹é›†è¨ˆç”¨ AIã‚¢ã‚·ã‚¹ãƒˆ
        # ==========================================
        with ai_tab1:
            st.subheader("Step 1: ã‚¯ãƒ­ã‚¹é›†è¨ˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼")
            prompt_cross = """# ã€çµ¶å¯¾éµå®ˆã®ãƒ«ãƒ¼ãƒ«ã€‘
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€Œé•·ããªã‚‹ã®ã§çœç•¥ã—ã¾ã™ã€ã€Œä»£è¡¨çš„ãªãƒˆãƒƒãƒ—3ã‚’æŒ™ã’ã¾ã™ã€ã¨ã„ã£ãŸè¦ç´„ã‚„çœç•¥ã‚’**çµ¶å¯¾ã«ã—ãªã„ã§ãã ã•ã„**ã€‚
- æ¡ä»¶ã«åˆè‡´ã™ã‚‹çµæœãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€**è¦‹ã¤ã‹ã£ãŸæ•°ã ã‘ã€ã™ã¹ã¦æ¼ã‚‰ã•ãšåˆ—æŒ™**ã—ã¦ãã ã•ã„ã€‚

# ä¾é ¼
æ·»ä»˜ã®ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ç«‹æ¡ˆã®ãŸã‚ã®è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»Šå›ã¯**ã€Œã‚¯ãƒ­ã‚¹é›†è¨ˆã€**ã«ã‚ˆã‚‹åˆ†æã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚

# åˆ†ææ‰‹æ³•ã¨è¦³ç‚¹
1. **ã‚¯ãƒ­ã‚¹é›†è¨ˆ**
   - å¹´ä»£ã€æ€§åˆ¥ã€å±…ä½å¹´æ•°ãªã©ã®åŸºæœ¬å±æ€§ã¨ã€æº€è¶³åº¦ã‚„æ„è­˜è¨­å•ã¨ã®æ›ã‘åˆã‚ã›ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
   - å„æ„è­˜ãƒ»æº€è¶³åº¦ã®Top2ï¼ˆè‚¯å®šæ´¾ï¼‰ã®å‰²åˆã®å·®åˆ†ãŒ15%ä»¥ä¸Šè¦‹ã‚‰ã‚ŒãŸçµ„ã¿åˆã‚ã›ã‚’**ã™ã¹ã¦**æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
   - ã•ã‚‰ã«ã€Bottom2ï¼ˆå¦å®šæ´¾ï¼‰ã®å‰²åˆã®å·®åˆ†ãŒ15%ä»¥ä¸Šè¦‹ã‚‰ã‚Œã‚‹çµ„ã¿åˆã‚ã›ã‚‚**ã™ã¹ã¦**æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›å½¢å¼
1. **åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆäººé–“ãŒèª­ã‚€ç”¨ï¼‰**
   - è¦‹å‡ºã—ã‚’ç«‹ã¦ã€ç®‡æ¡æ›¸ãã§è©³ç´°ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

2. **ã‚¢ãƒ—ãƒªé€£æºç”¨è¨­å®šãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰**
   - **æœ€å¾Œã«å¿…ãš**ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§è¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
   - **âš ï¸ã€é‡è¦ã€‘åˆ†æã‚µãƒãƒªãƒ¼ã§è¦‹ã¤ã‘ãŸã™ã¹ã¦ã®çµ„ã¿åˆã‚ã›ã‚’JSONã®ãƒªã‚¹ãƒˆã«å«ã‚ã¦ãã ã•ã„ã€‚çµ¶å¯¾ã«è¦‹ã¤ã‹ã£ãŸæ•°ã ã‘å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚**
   - **åˆ—åã¯ã€CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ­£ç¢ºãªåç§°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**

```json
{
  "cross_tab": [
    {"index": "åˆ—åA", "columns": "åˆ—åB"},
    {"index": "åˆ—åC", "columns": "åˆ—åD"}
    // ... è¦‹ã¤ã‘ãŸæ•°ã ã‘ã™ã¹ã¦è¨˜è¿°ã™ã‚‹
  ]
}
```"""
            st_copy_to_clipboard(prompt_cross, "ğŸ“‹ ã‚¯ãƒ­ã‚¹é›†è¨ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
            with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸­èº«ã‚’ç¢ºèª", expanded=False):
                st.code(prompt_cross, language="markdown")
            
            st.divider()
            st.subheader("Step 2: AIã®å›ç­”ã‚’è²¼ã‚Šä»˜ã‘")
            ai_input_cross = st.text_area("ã“ã“ã«AIã®å›ç­”ï¼ˆæœ€å¾Œã®JSONã¾ã§å«ã‚€ï¼‰ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=200, key="ta_cross")
            
            if ai_input_cross:
                config = extract_json_config(ai_input_cross)
                if config and "cross_tab" in config and isinstance(config['cross_tab'], list):
                    st.success("âœ… è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸï¼")
                    st.write(f"### ğŸ“ˆ ã‚¯ãƒ­ã‚¹é›†è¨ˆã®ãŠã™ã™ã‚ï¼ˆ{len(config['cross_tab'])}ä»¶ï¼‰")
                    cols = st.columns(2)
                    for i, setting in enumerate(config['cross_tab']):
                        col = cols[i % 2]
                        with col.expander(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1}: {setting.get('index')} Ã— {setting.get('columns')}", expanded=False):
                            st.write(f"**è¡Œ**: {setting.get('index')}")
                            st.write(f"**åˆ—**: {setting.get('columns')}")
                            st.button(f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}ã‚’é©ç”¨", key=f"btn_cross_{i}", on_click=cb_update_cross, args=(setting.get('index'), setting.get('columns')))
                elif config:
                    st.warning("JSONã¯èª­ã¿å–ã‚Œã¾ã—ãŸãŒã€'cross_tab' ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    st.error("JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # ==========================================
        # ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æç”¨ AIã‚¢ã‚·ã‚¹ãƒˆ
        # ==========================================
        with ai_tab2:
            st.subheader("Step 1: ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼")
            prompt_reg = """# ã€çµ¶å¯¾éµå®ˆã®ãƒ«ãƒ¼ãƒ«ã€‘
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã€Œé•·ããªã‚‹ã®ã§çœç•¥ã—ã¾ã™ã€ã€Œä»£è¡¨çš„ãªãƒˆãƒƒãƒ—3ã‚’æŒ™ã’ã¾ã™ã€ã¨ã„ã£ãŸè¦ç´„ã‚„çœç•¥ã‚’**çµ¶å¯¾ã«ã—ãªã„ã§ãã ã•ã„**ã€‚
- æ¡ä»¶ã«åˆè‡´ã™ã‚‹çµæœãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€**è¦‹ã¤ã‹ã£ãŸæ•°ã ã‘ã€ã™ã¹ã¦æ¼ã‚‰ã•ãšåˆ—æŒ™**ã—ã¦ãã ã•ã„ã€‚

# ä¾é ¼
æ·»ä»˜ã®ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ç«‹æ¡ˆã®ãŸã‚ã®è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»Šå›ã¯**ã€Œãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰ã€**ã«ã‚ˆã‚‹åˆ†æã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚

# åˆ†ææ‰‹æ³•ã¨è¦³ç‚¹
1. **ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰**
   - **âš ï¸é‡è¦: ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆå†…ã«ã‚ã‚‹ã€ŒçŠ¶æ…‹ã‚„æ„è­˜ã‚’å•ã†è¨­å•ï¼ˆä¾‹ï¼šæ„›ç€ã€ä½ã¿ã‚„ã™ã•ã€å¹¸ã›ã€è‰¯ãã—ãŸã„ã€è©•åˆ¤ãŒè‰¯ã„ç­‰ï¼‰ã€ã‚’ã€ã™ã¹ã¦ï¼ˆæœ€ä½ã§ã‚‚5é …ç›®ä»¥ä¸Šï¼‰ã€‘å€‹åˆ¥ã®ç›®çš„å¤‰æ•°ã¨ã—ã¦è¨­å®šã—ã€ãã‚Œãã‚Œå›å¸°åˆ†æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚**
   - èª¬æ˜å¤‰æ•°ï¼šåœ°åŸŸè¦ç´ ã‚„æº€è¶³åº¦ã«é–¢ã™ã‚‹è¨­å•ï¼ˆQ6ç³»ãªã©ï¼‰ã‚’ã™ã¹ã¦æŠ•å…¥ã—ã¦ãã ã•ã„ã€‚
   - ãã‚Œãã‚Œã®ç›®çš„å¤‰æ•°ã«å¯¾ã—ã€På€¤ãŒæœ‰æ„ï¼ˆ< 0.05ï¼‰ãªã‚‚ã®ã®ã†ã¡ã€ã‚ªãƒƒã‚ºæ¯”ãŒ1.0ã‚ˆã‚Šå¤§ãããƒ—ãƒ©ã‚¹ã®å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã‚‹è¦ç´ ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŒ–ã—ã¦ã™ã¹ã¦åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚
   - åŒæ™‚ã«ã€ã‚ªãƒƒã‚ºæ¯”ãŒ0.8ä»¥ä¸‹ã®ãƒã‚¤ãƒŠã‚¹ï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã®å½±éŸ¿ã‚’ä¸ãˆã¦ã„ã‚‹è¦ç´ ã‚‚åˆ†ã‘ã¦ã™ã¹ã¦åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›å½¢å¼
1. **åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆäººé–“ãŒèª­ã‚€ç”¨ï¼‰**
   - è¦‹å‡ºã—ã‚’ç«‹ã¦ã€ç®‡æ¡æ›¸ãã§è©³ç´°ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

2. **ã‚¢ãƒ—ãƒªé€£æºç”¨è¨­å®šãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰**
   - **æœ€å¾Œã«å¿…ãš**ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§è¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
   - **âš ï¸ã€é‡è¦ã€‘åˆ†æã—ãŸã™ã¹ã¦ã®ç›®çš„å¤‰æ•°ï¼ˆæœ€ä½ã§ã‚‚5é …ç›®ä»¥ä¸Šï¼‰ã‚’JSONã®ãƒªã‚¹ãƒˆã«å«ã‚ã¦ãã ã•ã„ã€‚çµ¶å¯¾ã«çœç•¥ã—ãªã„ã§ãã ã•ã„ã€‚**
   - **åˆ—åã¯ã€CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ­£ç¢ºãªåç§°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**

```json
{
  "driver_analysis": [
    {"target": "æ„è­˜è¨­å•1", "features": ["èª¬æ˜å¤‰æ•°1", "èª¬æ˜å¤‰æ•°2", "èª¬æ˜å¤‰æ•°3"]},
    {"target": "æ„è­˜è¨­å•2", "features": ["èª¬æ˜å¤‰æ•°1", "èª¬æ˜å¤‰æ•°4"]}
    // ... åˆ†æã—ãŸç›®çš„å¤‰æ•°ã®æ•°ã ã‘ã™ã¹ã¦è¨˜è¿°ã™ã‚‹
  ]
}
```"""
            st_copy_to_clipboard(prompt_reg, "ğŸ“‹ ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
            with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸­èº«ã‚’ç¢ºèª", expanded=False):
                st.code(prompt_reg, language="markdown")
            
            st.divider()
            st.subheader("Step 2: AIã®å›ç­”ã‚’è²¼ã‚Šä»˜ã‘")
            ai_input_reg = st.text_area("ã“ã“ã«AIã®å›ç­”ï¼ˆæœ€å¾Œã®JSONã¾ã§å«ã‚€ï¼‰ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=200, key="ta_reg")
            
            if ai_input_reg:
                config = extract_json_config(ai_input_reg)
                if config and "driver_analysis" in config and isinstance(config['driver_analysis'], list):
                    st.success("âœ… è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸï¼")
                    st.write(f"### ğŸš€ ãƒ‰ãƒ©ã‚¤ãƒãƒ¼åˆ†æã®ãŠã™ã™ã‚ï¼ˆ{len(config['driver_analysis'])}ä»¶ï¼‰")
                    cols = st.columns(2)
                    for i, setting in enumerate(config['driver_analysis']):
                        tgt = setting.get('target')
                        feats = setting.get('features', [])
                        col = cols[i % 2]
                        with col.expander(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1}: {tgt}", expanded=False):
                            st.write(f"**ç›®çš„**: {tgt}")
                            st.caption(f"**è¦å› **: {', '.join(feats)}")
                            valid_feats_reg = [f for f in feats if f in df.columns]
                            st.button(f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}ã‚’é©ç”¨", key=f"btn_reg_{i}", on_click=cb_update_reg, args=(tgt, valid_feats_reg))
                elif config:
                    st.warning("JSONã¯èª­ã¿å–ã‚Œã¾ã—ãŸãŒã€'driver_analysis' ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    st.error("JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # ==========================================
        # æ±ºå®šæœ¨åˆ†æç”¨ AIã‚¢ã‚·ã‚¹ãƒˆ
        # ==========================================
        with ai_tab3:
            st.subheader("Step 1: æ±ºå®šæœ¨åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼")
            prompt_tree = """# ä¾é ¼
æ·»ä»˜ã®ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ç«‹æ¡ˆã®ãŸã‚ã®è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»Šå›ã¯**ã€Œæ±ºå®šæœ¨åˆ†æã€**ã«ã‚ˆã‚‹åˆ†æã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚

# åˆ†ææ‰‹æ³•ã¨è¦³ç‚¹
1. **æ±ºå®šæœ¨åˆ†æ**
   - ç›®çš„å¤‰æ•°ï¼šã€ŒçŠ¶æ…‹ã€ã‚„ã€Œä½“æ„Ÿãƒ»æº€è¶³åº¦ã€ã€Œæ¨å¥¨æ„å‘ã€ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã‚„ã€Œç”Ÿæ´»ç¿’æ…£ãƒ»è¡Œå‹•ã€ã¸ã®å½±éŸ¿ãªã©ã®é‡è¦æŒ‡æ¨™ã‚’è¤‡æ•°è¨­å®šã—ã¦ãã ã•ã„ã€‚
   - ã©ã®ã‚ˆã†ãªæ¡ä»¶ãŒé‡ãªã‚‹ã¨ã€ãã®é‡è¦æŒ‡æ¨™ãŒé«˜ããªã‚‹ï¼ˆã¾ãŸã¯ä½ããªã‚‹ï¼‰ã‹ã®åˆ†å²ãƒ«ãƒ¼ãƒ«ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›å½¢å¼
1. **åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆäººé–“ãŒèª­ã‚€ç”¨ï¼‰**
   - è¦‹å‡ºã—ã‚’ç«‹ã¦ã€ç®‡æ¡æ›¸ãã§è©³ç´°ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

2. **ã‚¢ãƒ—ãƒªé€£æºç”¨è¨­å®šãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰**
   - **æœ€å¾Œã«å¿…ãš**ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§3ã¤ä»¥ä¸Šã®è¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
   - **åˆ—åã¯ã€CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ­£ç¢ºãªåç§°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**

```json
{
  "decision_tree": [
    {"target": "ç›®çš„å¤‰æ•°A", "features": ["èª¬æ˜å¤‰æ•°1", "èª¬æ˜å¤‰æ•°2", "èª¬æ˜å¤‰æ•°3"]},
    {"target": "ç›®çš„å¤‰æ•°B", "features": ["èª¬æ˜å¤‰æ•°1", "èª¬æ˜å¤‰æ•°4", "èª¬æ˜å¤‰æ•°5"]}
  ]
}
```"""
            st_copy_to_clipboard(prompt_tree, "ğŸ“‹ æ±ºå®šæœ¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
            with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸­èº«ã‚’ç¢ºèª", expanded=False):
                st.code(prompt_tree, language="markdown")
            
            st.divider()
            st.subheader("Step 2: AIã®å›ç­”ã‚’è²¼ã‚Šä»˜ã‘")
            ai_input_tree = st.text_area("ã“ã“ã«AIã®å›ç­”ï¼ˆæœ€å¾Œã®JSONã¾ã§å«ã‚€ï¼‰ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=200, key="ta_tree")
            
            if ai_input_tree:
                config = extract_json_config(ai_input_tree)
                if config and "decision_tree" in config and isinstance(config['decision_tree'], list):
                    st.success("âœ… è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸï¼")
                    st.write(f"### ğŸŒ³ æ±ºå®šæœ¨ã®ãŠã™ã™ã‚ï¼ˆ{len(config['decision_tree'])}ä»¶ï¼‰")
                    cols = st.columns(2)
                    for i, setting in enumerate(config['decision_tree']):
                        tgt = setting.get('target')
                        feats = setting.get('features', [])
                        col = cols[i % 2]
                        with col.expander(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1}: {tgt}", expanded=False):
                            st.write(f"**ç›®çš„**: {tgt}")
                            st.caption(f"**è¦å› **: {', '.join(feats)}")
                            valid_feats = [f for f in feats if f in df.columns]
                            st.button(f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}ã‚’é©ç”¨", key=f"btn_tree_{i}", on_click=cb_update_tree, args=(tgt, valid_feats))
                elif config:
                    st.warning("JSONã¯èª­ã¿å–ã‚Œã¾ã—ãŸãŒã€'decision_tree' ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    st.error("JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # ==========================================
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æç”¨ AIã‚¢ã‚·ã‚¹ãƒˆ
        # ==========================================
        with ai_tab4:
            st.subheader("Step 1: ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼")
            prompt_cluster = """# ä¾é ¼
æ·»ä»˜ã®ã‚¢ãƒ³ã‚±ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æˆ¦ç•¥ç«‹æ¡ˆã®ãŸã‚ã®è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ä»Šå›ã¯**ã€Œã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã€**ã«ã‚ˆã‚‹åˆ†æã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚

# åˆ†ææ‰‹æ³•ã¨è¦³ç‚¹
1. **ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æ**
   - å›ç­”å‚¾å‘ãŒä¼¼ã¦ã„ã‚‹å›ç­”è€…ã‚’ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ï¼ˆ3ã€œ5ã‚°ãƒ«ãƒ¼ãƒ—ç¨‹åº¦ï¼‰ã—ã¦ãã ã•ã„ã€‚
   - å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ç‰¹å¾´ï¼ˆä½•ã«æº€è¶³ã—ã€ä½•ã«ä¸æº€ã‹ï¼‰ã¨ã€å‘½åï¼ˆãƒšãƒ«ã‚½ãƒŠåï¼‰ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›å½¢å¼
1. **åˆ†æã‚µãƒãƒªãƒ¼ï¼ˆäººé–“ãŒèª­ã‚€ç”¨ï¼‰**
   - è¦‹å‡ºã—ã‚’ç«‹ã¦ã€ç®‡æ¡æ›¸ãã§è©³ç´°ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚

2. **ã‚¢ãƒ—ãƒªé€£æºç”¨è¨­å®šãƒ‡ãƒ¼ã‚¿ï¼ˆJSONå½¢å¼ï¼‰**
   - **æœ€å¾Œã«å¿…ãš**ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§3ã¤ä»¥ä¸Šã®è¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä½¿ç”¨ã™ã‚‹å¤‰æ•°ã®çµ„ã¿åˆã‚ã›ã¨ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ï¼‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
   - **åˆ—åã¯ã€CSVã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«ã‚ã‚‹æ­£ç¢ºãªåç§°ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**

```json
{
  "clustering": [
    {"features": ["å¤‰æ•°1", "å¤‰æ•°2", "å¤‰æ•°3"], "n_clusters": 4},
    {"features": ["å¤‰æ•°1", "å¤‰æ•°4", "å¤‰æ•°5"], "n_clusters": 3}
  ]
}
```"""
            st_copy_to_clipboard(prompt_cluster, "ğŸ“‹ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ”ãƒ¼", "âœ… ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸï¼")
            with st.expander("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¸­èº«ã‚’ç¢ºèª", expanded=False):
                st.code(prompt_cluster, language="markdown")
            
            st.divider()
            st.subheader("Step 2: AIã®å›ç­”ã‚’è²¼ã‚Šä»˜ã‘")
            ai_input_cluster = st.text_area("ã“ã“ã«AIã®å›ç­”ï¼ˆæœ€å¾Œã®JSONã¾ã§å«ã‚€ï¼‰ã‚’è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=200, key="ta_cluster")
            
            if ai_input_cluster:
                config = extract_json_config(ai_input_cluster)
                if config and "clustering" in config and isinstance(config['clustering'], list):
                    st.success("âœ… è¨­å®šãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å–ã‚Šã¾ã—ãŸï¼")
                    st.write(f"### ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†æã®ãŠã™ã™ã‚ï¼ˆ{len(config['clustering'])}ä»¶ï¼‰")
                    cols = st.columns(2)
                    for i, setting in enumerate(config['clustering']):
                        feats = setting.get('features', [])
                        col = cols[i % 2]
                        with col.expander(f"ãƒ‘ã‚¿ãƒ¼ãƒ³ {i+1}: {len(feats)}å¤‰æ•°ã§åˆ†é¡", expanded=False):
                            st.caption(f"**å¤‰æ•°**: {', '.join(feats)}")
                            valid_feats_cluster = [f for f in feats if f in df.columns]
                            st.button(f"ãƒ‘ã‚¿ãƒ¼ãƒ³{i+1}ã‚’é©ç”¨", key=f"btn_cluster_{i}", on_click=cb_update_cluster, args=(valid_feats_cluster,))
                elif config:
                    st.warning("JSONã¯èª­ã¿å–ã‚Œã¾ã—ãŸãŒã€'clustering' ã®è¨­å®šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                else:
                    st.error("JSONãƒ‡ãƒ¼ã‚¿ã®èª­ã¿å–ã‚Šã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

else:
    st.info("ğŸ‘ˆ å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
